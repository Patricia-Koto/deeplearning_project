# app.py
# D√©pendances :
#   pip install "tensorflow>=2.12" "keras>=3.0" streamlit pillow matplotlib

import io
import pathlib
import numpy as np
import streamlit as st
import tensorflow as tf
from PIL import Image
from tensorflow.keras.preprocessing import image as kimage
import keras  # pour charger correctement le format .keras (Keras 3)

tfk = tf.keras

st.set_page_config(page_title="Scenes Classifier", page_icon="üñºÔ∏è", layout="centered")

# ========= CONFIG =========
DEFAULT_MODEL_PATH = "transfer_best.keras"
IMG_SIZE = (150, 150)
CLASS_NAMES = ["buildings", "forest", "glacier", "mountain", "sea", "street"]

# ========= UTILS =========
def any_layer_recursive(layer, predicate) -> bool:
    if predicate(layer):
        return True
    for sub in getattr(layer, "layers", []):
        if any_layer_recursive(sub, predicate):
            return True
    return False

def model_has_rescaling(model) -> bool:
    return any_layer_recursive(model, lambda l: isinstance(l, tfk.layers.Rescaling))

def preprocess_for_model(x_uint8: np.ndarray, has_rescaling: bool) -> np.ndarray:
    x = x_uint8.astype("float32")
    if not has_rescaling:
        x = x / 255.0
    return x

# ========= CACHES =========
@st.cache_resource(show_spinner=True)
def load_model(model_path: str):
    try:
        # Keras 3 (.keras)
        return keras.models.load_model(model_path, compile=False, safe_mode=False)
    except Exception:
        # tf.keras (SavedModel/H5)
        return tfk.models.load_model(model_path, compile=False)

@st.cache_data(show_spinner=False)
def read_image(file_bytes: bytes, size=(150, 150)):
    img = Image.open(io.BytesIO(file_bytes)).convert("RGB")
    img_resized = img.resize(size)
    x = kimage.img_to_array(img_resized)     # (H,W,3) float32 [0..255]
    x = np.expand_dims(x, axis=0)            # (1,H,W,3)
    return img, img_resized, x

# ========= UI =========
st.title("üñºÔ∏è Intel Scenes ‚Äî Pr√©diction simple (sans Grad-CAM)")
st.caption("Charge un mod√®le .keras/.h5, envoie une image, et vois la pr√©diction.")

# Choix mod√®le + Top-k
colA, colB = st.columns([2, 1])
with colA:
    model_path = st.text_input("Chemin du mod√®le", DEFAULT_MODEL_PATH)
with colB:
    topk = st.number_input("Top-k", min_value=1, max_value=len(CLASS_NAMES), value=3)
st.caption("""
**‚ÑπÔ∏è Top-k** : affiche les k classes les plus probables, tri√©es de la plus certaine √† la moins certaine.  
""")
# Chargement mod√®le
try:
    model = load_model(model_path)
    HAS_RESCALING = model_has_rescaling(model)
    st.success("Mod√®le charg√©.")
except Exception as e:
    st.error(f"Impossible de charger le mod√®le : {e}")
    st.stop()

# ========= Uploader (multi) + Pr√©diction =========
uploaded_files = st.file_uploader(
    "Glisse une ou plusieurs images (JPG/PNG)‚Ä¶",
    type=["jpg", "jpeg", "png"],
    accept_multiple_files=True  # <‚Äî la seule option √† ajouter
)

if uploaded_files:
    for file in uploaded_files:
        # Lecture + pr√©traitement
        pil_img, pil_resized, x_uint8 = read_image(file.read(), size=IMG_SIZE)
        x = preprocess_for_model(x_uint8, HAS_RESCALING)

        # Aper√ßu
        st.subheader(f"Aper√ßu ‚Äî {file.name}")
        st.image(pil_img, caption="Image originale", use_container_width=True)

        # Pr√©diction (appel direct)
        y = model(tf.convert_to_tensor(x, dtype=tf.float32), training=False).numpy()[0]
        # Si le mod√®le renvoie des logits, applique softmax
        if np.any(y < 0) or not np.isclose(np.sum(y), 1.0, atol=1e-3):
            y = tf.nn.softmax(y).numpy()

        idx_sorted = y.argsort()[::-1][:topk]
        st.subheader("Pr√©dictions")
        for i in idx_sorted:
            st.write(f"- **{CLASS_NAMES[i]}** : {y[i]:.2%}")
        st.progress(float(y[idx_sorted[0]]))

